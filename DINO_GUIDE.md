# ğŸ§  DINOv2 Self-Supervised Learning Guide

## ğŸ¯ Overview

Táº¡o **self-supervised visual encoder** vá»›i **DINOv2** technique rá»“i fine-tune cho Mouse vs AI task!

**Pipeline:**
```
Unity Env â†’ Visual Data â†’ DINOv2 Pre-training â†’ RL Fine-tuning â†’ Better Performance! ğŸš€
```

## ğŸ”„ Complete Workflow

### **âš¡ Quick Start (One Command):**
```bash
# Run complete workflow
python dino_workflow.py --step all

# Or step by step
python dino_workflow.py --step collect    # 1. Collect data
python dino_workflow.py --step pretrain   # 2. Pre-train DINOv2  
python dino_workflow.py --step setup      # 3. Setup encoder
python dino_workflow.py --step finetune   # 4. RL fine-tuning
```

### **ğŸ“Š Step-by-Step Guide:**

## **1. ğŸ“¸ Data Collection**

Thu tháº­p visual observations tá»« Unity environments:

```bash
# Collect from single environment
python data_collector.py --env NormalTrain --episodes 100 --steps 500 --output ./dataset_mouse --split

# Collect from multiple environments (more diverse data)
python data_collector.py --env FogTrain --episodes 50 --output ./dataset_fog --split
python data_collector.py --env RandomTrain --episodes 50 --output ./dataset_random --split
```

**ğŸ’¾ Output structure:**
```
dataset_mouse/
â”œâ”€â”€ images/           # Raw images (PNG format)
â”‚   â”œâ”€â”€ img_000001_ep0_step10_agent0.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ train/           # Training split (80%)
â”œâ”€â”€ val/             # Validation split (20%)  
â””â”€â”€ metadata/        # Collection info
    â””â”€â”€ collection_info.yaml
```

**ğŸ¯ Tips:**
- **Nhiá»u episodes** = more diverse data
- **Mix environments** = better generalization
- **Random policy** = unbiased data collection

---

## **2. ğŸ§  DINOv2 Pre-training**

Self-supervised pre-training vá»›i DINOv2:

```bash
# Basic pre-training
python dino_pretrain.py --data ./dataset_mouse/train --output ./dino_checkpoints

# With custom config
python dino_pretrain.py --data ./dataset_mouse/train --config dino_config.yaml --output ./dino_checkpoints

# With Weights & Biases logging
python dino_pretrain.py --data ./dataset_mouse/train --wandb --output ./dino_checkpoints
```

**âš™ï¸ DINOv2 Configuration:**
```yaml
# dino_config.yaml
model:
  img_size: 224
  patch_size: 16
  embed_dim: 384      # Model size
  depth: 6           # Transformer layers
  num_heads: 6       # Attention heads

training:
  epochs: 50         # Pre-training epochs
  batch_size: 32     # Adjust for GPU memory
  teacher_momentum: 0.996

optimizer:
  lr: 5e-4          # Learning rate
  weight_decay: 0.04
```

**ğŸ“Š Expected Training Time:**
- **Small dataset** (10k images): ~2 hours
- **Large dataset** (100k images): ~20 hours  
- **RTX 4060**: ~3-4 images/sec

---

## **3. ğŸ”§ RL Integration**

Sá»­ dá»¥ng pre-trained DINOv2 lÃ m encoder:

### **A. Encoder Setup:**
File `Encoders/dino_encoder.py` Ä‘Ã£ Ä‘Æ°á»£c táº¡o sáºµn vá»›i:
- âœ… DINOv2 Vision Transformer backbone
- âœ… Pre-trained weight loading
- âœ… ML-Agents compatibility
- âœ… Fine-tuning options

### **B. Training vá»›i DINOv2:**
```bash
# Quick training
python train_easy.py --model dino_encoder --runs 3 --steps 50000 --resume

# Advanced training
python train_advanced.py --config config_examples/dino_finetuning.yaml
```

### **C. Fine-tuning Strategies:**

**ğŸ”’ Frozen Features (Fastest):**
```python
# In dino_encoder.py
self.freeze_backbone = True  # Keep backbone frozen
```

**ğŸ”“ Partial Fine-tuning (Recommended):**
```python
# Unfreeze last 2 layers
encoder.unfreeze_backbone(unfreeze_last_n_layers=2)
```

**ğŸ”¥ Full Fine-tuning (Best Performance):**
```python
# Unfreeze all layers
encoder.unfreeze_backbone(unfreeze_last_n_layers=6)  # All layers
```

---

## **4. ğŸ“Š Evaluation & Comparison**

So sÃ¡nh DINOv2 vá»›i baselines:

```bash
# Train baseline models
python train_advanced.py --config config_examples/ablation_study.yaml

# Train DINOv2 model  
python train_advanced.py --config config_examples/dino_finetuning.yaml

# Evaluate on test environment
python evaluate.py --model "path/to/dino_model.onnx" --env RandomTest --episodes 100 --log-name "dino_test"
python evaluate.py --model "path/to/baseline_model.onnx" --env RandomTest --episodes 100 --log-name "baseline_test"
```

---

## **ğŸ’¡ Advanced Usage**

### **ğŸ›ï¸ Hyperparameter Tuning:**

```yaml
# config_examples/dino_hyperparameter_sweep.yaml
hyperparameters:
  sweep_params:
    # Fine-tuning specific params
    behaviors.My Behavior.hyperparameters.learning_rate: 
      - 0.00005  # Very low for pre-trained
      - 0.0001   # Standard fine-tuning
      - 0.0003   # Higher for more adaptation
    
    # Unfreeze different amounts
    unfreeze_layers: [1, 2, 3]  # Custom parameter
    
    behaviors.My Behavior.hyperparameters.batch_size: [64, 128, 256]
```

### **ğŸ”¬ Ablation Studies:**

Test different configurations:

```bash
# 1. Random initialization (no pre-training)
python train_easy.py --model nature_cnn --runs 5

# 2. Frozen DINOv2 features
python train_easy.py --model dino_encoder --runs 5  

# 3. Fine-tuned DINOv2 (last 2 layers)
# Edit dino_encoder.py: encoder.unfreeze_backbone(2)
python train_easy.py --model dino_encoder --runs 5

# 4. Full fine-tuning
# Edit dino_encoder.py: encoder.unfreeze_backbone(6)  
python train_easy.py --model dino_encoder --runs 5
```

---

## **ğŸ“ˆ Expected Results**

### **Performance Improvements:**

| Method | Success Rate | Training Time | Notes |
|--------|-------------|---------------|-------|
| Nature CNN (baseline) | ~75% | 2 hours | Random initialization |
| Frozen DINOv2 | ~80% | 1 hour | Fast convergence |
| Fine-tuned DINOv2 | ~85%+ | 3 hours | Best performance |

### **Why DINOv2 Works Better:**

1. **ğŸ¯ Better Visual Representations**: Learns general visual features
2. **âš¡ Faster Convergence**: Pre-trained features reduce training time  
3. **ğŸª Better Generalization**: Works better on FogTrain/RandomTest
4. **ğŸ“Š Data Efficiency**: Needs less RL training data

---

## **ğŸ› Troubleshooting**

### **Data Collection Issues:**
```bash
# Check environment exists
ls Builds/NormalTrain/

# Test with fewer episodes first
python data_collector.py --env NormalTrain --episodes 10 --steps 100
```

### **Pre-training Issues:**
```bash
# GPU memory issues - reduce batch size
# Edit dino_config.yaml: batch_size: 16

# Dataset too small warning - collect more data
python data_collector.py --episodes 200 --steps 1000
```

### **RL Training Issues:**
```bash
# Check pre-trained weights loaded
# Look for: "âœ… Pre-trained weights loaded successfully!"

# If weights not found, check path:
ls dino_checkpoints/best_checkpoint.pth
```

---

## **ğŸ¯ Quick Commands Summary**

```bash
# ğŸš€ Complete workflow (one command)
python dino_workflow.py

# ğŸ“Š Quick comparison
python train_easy.py --model nature_cnn --runs 3    # Baseline
python train_easy.py --model dino_encoder --runs 3   # DINOv2

# ğŸ” Analysis
python config_analyzer.py config_examples/dino_finetuning.yaml
```

---

## **ğŸ“š Technical Details**

### **DINOv2 Architecture:**
- **Vision Transformer** with 6 layers, 6 heads, 384 embedding dim
- **Patch size**: 16x16 pixels
- **Input resolution**: 224x224 (resized from 155x86)
- **Output**: 384-dimensional features

### **Self-Supervised Loss:**
- **Teacher-Student framework** vá»›i EMA updates
- **Cross-entropy loss** between teacher/student predictions
- **Centering mechanism** Ä‘á»ƒ trÃ¡nh collapse

### **Integration Benefits:**
- âœ… **Drop-in replacement** cho existing encoders
- âœ… **GPU accelerated** vá»›i CUDA support
- âœ… **Memory efficient** vá»›i frozen backbone option
- âœ… **Scalable** to larger datasets/models

---

**ğŸ‰ Happy self-supervised learning! ChÃºc báº¡n train ra model siÃªu máº¡nh!** ğŸš€
